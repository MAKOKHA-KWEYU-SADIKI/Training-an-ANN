{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e7412f3d",
      "metadata": {
        "id": "e7412f3d"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "68472d72",
      "metadata": {
        "id": "68472d72"
      },
      "outputs": [],
      "source": [
        "dataset=pd.read_csv(\"/content/diabetes.csv\")\n",
        "#print(dataset.head(3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "8bb3ddf4",
      "metadata": {
        "id": "8bb3ddf4"
      },
      "outputs": [],
      "source": [
        "x=dataset.iloc[:,:-1].values\n",
        "y=dataset.iloc[:,-1].values\n",
        "#print(x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "imputer=SimpleImputer(missing_values=np.nan,strategy='mean')\n",
        "imputer.fit(x[:,:])\n",
        "x[:,:]=imputer.transform(x[:,:])\n",
        "#print(x)"
      ],
      "metadata": {
        "id": "ty5Uo24YWXER"
      },
      "id": "ty5Uo24YWXER",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc=StandardScaler()\n",
        "x=sc.fit_transform(x)\n",
        "#print(x)"
      ],
      "metadata": {
        "id": "_ynmtvjCYtUi"
      },
      "id": "_ynmtvjCYtUi",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "CdORxPR6eufG",
      "metadata": {
        "id": "CdORxPR6eufG"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=.2,random_state=1)\n",
        "#print(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "jE1dM0TnOQuM",
      "metadata": {
        "id": "jE1dM0TnOQuM"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "model=Sequential([\n",
        "    Dense(10,activation='relu'),\n",
        "    Dense(10,activation='relu'),\n",
        "    Dense(2,activation='softmax')\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# model = Sequential([\n",
        "#     Dense(32, activation='relu', input_shape=(x_train.shape[1],)),\n",
        "#     Dense(1, activation='sigmoid')  # For binary classification\n",
        "# ])\n",
        "# # Train the model\n",
        "# from tensorflow.keras.optimizers import RMSprop\n",
        "# from sklearn.utils.class_weight import compute_class_weight\n",
        "# classes = np.unique(y_train)\n",
        "# class_weights = compute_class_weight('balanced', classes=classes, y=y_train)\n",
        "# class_weight_dict = dict(zip(classes, class_weights))\n",
        "# model.compile(optimizer=RMSprop(learning_rate=0.005),\n",
        "#               loss='binary_crossentropy',\n",
        "#               metrics=['accuracy'])\n",
        "# from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "# lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)\n",
        "# model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=20, batch_size=32,\n",
        "#           class_weight=class_weight_dict, callbacks=[lr_scheduler])\n",
        "# # Evaluate the model\n",
        "# y_pred = (model.predict(x_test) > 0.5).astype(int)\n",
        "# print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LeakyReLU, BatchNormalization, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import BinaryFocalCrossentropy\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Define the model with additional optimizations\n",
        "model = Sequential([\n",
        "    Dense(64, input_shape=(x_train.shape[1],), activation=None),  # No activation for input layer\n",
        "    BatchNormalization(),\n",
        "    LeakyReLU(alpha=0.01),  # LeakyReLU to prevent dead neurons\n",
        "    Dropout(0.5),  # Dropout for regularization\n",
        "    Dense(32, activation=None),  # Second hidden layer\n",
        "    BatchNormalization(),\n",
        "    LeakyReLU(alpha=0.01),\n",
        "    Dropout(0.3),  # Dropout to prevent overfitting\n",
        "    Dense(1, activation='sigmoid')  # Sigmoid for binary classification\n",
        "])\n",
        "\n",
        "# Compute class weights to handle class imbalance\n",
        "classes = np.unique(y_train)\n",
        "class_weights = compute_class_weight('balanced', classes=classes, y=y_train)\n",
        "class_weight_dict = dict(zip(classes, class_weights))\n",
        "\n",
        "# Compile the model with Adam optimizer and BinaryFocalCrossentropy loss\n",
        "model.compile(optimizer=Adam(learning_rate=0.0037),\n",
        "              loss=BinaryFocalCrossentropy(gamma=2.0),  # Focal loss for imbalanced data\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Define the learning rate scheduler\n",
        "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)\n",
        "\n",
        "# Train the model with class weights and callbacks\n",
        "history = model.fit(x_train, y_train,\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    epochs=50,\n",
        "                    batch_size=32,\n",
        "                    class_weight=class_weight_dict,\n",
        "                    callbacks=[lr_scheduler])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = (model.predict(x_test) > 0.5).astype(int)  # Threshold at 0.5 for sigmoid outputs\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "r07bT3CuaJ4Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47dfa2f6-445a-42f2-e98c-f5d8eb1132df"
      },
      "id": "r07bT3CuaJ4Q",
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.5702 - loss: 0.2546 - val_accuracy: 0.7468 - val_loss: 0.1427 - learning_rate: 0.0037\n",
            "Epoch 2/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6927 - loss: 0.1734 - val_accuracy: 0.7597 - val_loss: 0.1385 - learning_rate: 0.0037\n",
            "Epoch 3/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7016 - loss: 0.1698 - val_accuracy: 0.7273 - val_loss: 0.1407 - learning_rate: 0.0037\n",
            "Epoch 4/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7010 - loss: 0.1498 - val_accuracy: 0.7597 - val_loss: 0.1383 - learning_rate: 0.0037\n",
            "Epoch 5/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7210 - loss: 0.1401 - val_accuracy: 0.7662 - val_loss: 0.1340 - learning_rate: 0.0037\n",
            "Epoch 6/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6748 - loss: 0.1568 - val_accuracy: 0.7727 - val_loss: 0.1339 - learning_rate: 0.0037\n",
            "Epoch 7/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7380 - loss: 0.1511 - val_accuracy: 0.7532 - val_loss: 0.1313 - learning_rate: 0.0037\n",
            "Epoch 8/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7564 - loss: 0.1374 - val_accuracy: 0.7597 - val_loss: 0.1320 - learning_rate: 0.0037\n",
            "Epoch 9/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7144 - loss: 0.1349 - val_accuracy: 0.7532 - val_loss: 0.1296 - learning_rate: 0.0037\n",
            "Epoch 10/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7340 - loss: 0.1331 - val_accuracy: 0.7792 - val_loss: 0.1291 - learning_rate: 0.0037\n",
            "Epoch 11/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7220 - loss: 0.1440 - val_accuracy: 0.7727 - val_loss: 0.1301 - learning_rate: 0.0037\n",
            "Epoch 12/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7564 - loss: 0.1346 - val_accuracy: 0.7792 - val_loss: 0.1302 - learning_rate: 0.0037\n",
            "Epoch 13/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7432 - loss: 0.1333 - val_accuracy: 0.7792 - val_loss: 0.1288 - learning_rate: 0.0037\n",
            "Epoch 14/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7227 - loss: 0.1383 - val_accuracy: 0.7987 - val_loss: 0.1284 - learning_rate: 0.0037\n",
            "Epoch 15/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7258 - loss: 0.1314 - val_accuracy: 0.8052 - val_loss: 0.1248 - learning_rate: 0.0037\n",
            "Epoch 16/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7064 - loss: 0.1333 - val_accuracy: 0.7922 - val_loss: 0.1255 - learning_rate: 0.0037\n",
            "Epoch 17/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7239 - loss: 0.1368 - val_accuracy: 0.7987 - val_loss: 0.1295 - learning_rate: 0.0037\n",
            "Epoch 18/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7066 - loss: 0.1303 - val_accuracy: 0.7987 - val_loss: 0.1291 - learning_rate: 0.0037\n",
            "Epoch 19/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7086 - loss: 0.1272 - val_accuracy: 0.7922 - val_loss: 0.1285 - learning_rate: 0.0019\n",
            "Epoch 20/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7251 - loss: 0.1331 - val_accuracy: 0.7857 - val_loss: 0.1290 - learning_rate: 0.0019\n",
            "Epoch 21/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7180 - loss: 0.1380 - val_accuracy: 0.7857 - val_loss: 0.1287 - learning_rate: 0.0019\n",
            "Epoch 22/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7271 - loss: 0.1296 - val_accuracy: 0.7857 - val_loss: 0.1282 - learning_rate: 9.2500e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7548 - loss: 0.1212 - val_accuracy: 0.7922 - val_loss: 0.1276 - learning_rate: 9.2500e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7385 - loss: 0.1401 - val_accuracy: 0.7922 - val_loss: 0.1275 - learning_rate: 9.2500e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7856 - loss: 0.1199 - val_accuracy: 0.7922 - val_loss: 0.1272 - learning_rate: 4.6250e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7232 - loss: 0.1362 - val_accuracy: 0.7922 - val_loss: 0.1270 - learning_rate: 4.6250e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7329 - loss: 0.1229 - val_accuracy: 0.7922 - val_loss: 0.1272 - learning_rate: 4.6250e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7407 - loss: 0.1262 - val_accuracy: 0.7922 - val_loss: 0.1270 - learning_rate: 2.3125e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7199 - loss: 0.1304 - val_accuracy: 0.7922 - val_loss: 0.1270 - learning_rate: 2.3125e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7219 - loss: 0.1282 - val_accuracy: 0.7922 - val_loss: 0.1272 - learning_rate: 2.3125e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7396 - loss: 0.1275 - val_accuracy: 0.7922 - val_loss: 0.1275 - learning_rate: 1.1563e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7585 - loss: 0.1331 - val_accuracy: 0.7922 - val_loss: 0.1276 - learning_rate: 1.1563e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7458 - loss: 0.1264 - val_accuracy: 0.7922 - val_loss: 0.1276 - learning_rate: 1.1563e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6896 - loss: 0.1376 - val_accuracy: 0.7922 - val_loss: 0.1279 - learning_rate: 5.7813e-05\n",
            "Epoch 35/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7311 - loss: 0.1325 - val_accuracy: 0.7922 - val_loss: 0.1278 - learning_rate: 5.7813e-05\n",
            "Epoch 36/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7575 - loss: 0.1282 - val_accuracy: 0.7922 - val_loss: 0.1278 - learning_rate: 5.7813e-05\n",
            "Epoch 37/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7557 - loss: 0.1317 - val_accuracy: 0.7792 - val_loss: 0.1280 - learning_rate: 2.8906e-05\n",
            "Epoch 38/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7225 - loss: 0.1351 - val_accuracy: 0.7792 - val_loss: 0.1280 - learning_rate: 2.8906e-05\n",
            "Epoch 39/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7235 - loss: 0.1302 - val_accuracy: 0.7922 - val_loss: 0.1278 - learning_rate: 2.8906e-05\n",
            "Epoch 40/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7154 - loss: 0.1356 - val_accuracy: 0.7922 - val_loss: 0.1278 - learning_rate: 1.4453e-05\n",
            "Epoch 41/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7396 - loss: 0.1252 - val_accuracy: 0.7922 - val_loss: 0.1279 - learning_rate: 1.4453e-05\n",
            "Epoch 42/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7450 - loss: 0.1262 - val_accuracy: 0.7922 - val_loss: 0.1275 - learning_rate: 1.4453e-05\n",
            "Epoch 43/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7333 - loss: 0.1341 - val_accuracy: 0.7922 - val_loss: 0.1277 - learning_rate: 7.2266e-06\n",
            "Epoch 44/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6990 - loss: 0.1493 - val_accuracy: 0.7922 - val_loss: 0.1278 - learning_rate: 7.2266e-06\n",
            "Epoch 45/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7461 - loss: 0.1261 - val_accuracy: 0.7857 - val_loss: 0.1281 - learning_rate: 7.2266e-06\n",
            "Epoch 46/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7373 - loss: 0.1270 - val_accuracy: 0.7857 - val_loss: 0.1282 - learning_rate: 3.6133e-06\n",
            "Epoch 47/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7495 - loss: 0.1331 - val_accuracy: 0.7857 - val_loss: 0.1282 - learning_rate: 3.6133e-06\n",
            "Epoch 48/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7631 - loss: 0.1316 - val_accuracy: 0.7922 - val_loss: 0.1282 - learning_rate: 3.6133e-06\n",
            "Epoch 49/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7805 - loss: 0.1225 - val_accuracy: 0.7922 - val_loss: 0.1283 - learning_rate: 1.8066e-06\n",
            "Epoch 50/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7390 - loss: 0.1266 - val_accuracy: 0.7922 - val_loss: 0.1282 - learning_rate: 1.8066e-06\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.78      0.83        99\n",
            "           1       0.67      0.82      0.74        55\n",
            "\n",
            "    accuracy                           0.79       154\n",
            "   macro avg       0.78      0.80      0.78       154\n",
            "weighted avg       0.81      0.79      0.80       154\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "id": "Mrnyjq2HRxvk",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mrnyjq2HRxvk",
        "outputId": "74d8dc2e-3d39-40a2-e4d3-8b2be9defa50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7792 - loss: 0.1284\n",
            "Epoch 2/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7440 - loss: 0.1299 \n",
            "Epoch 3/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7738 - loss: 0.1229 \n",
            "Epoch 4/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7591 - loss: 0.1247 \n",
            "Epoch 5/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7281 - loss: 0.1289 \n",
            "Epoch 6/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7367 - loss: 0.1395\n",
            "Epoch 7/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7119 - loss: 0.1337 \n",
            "Epoch 8/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7562 - loss: 0.1231 \n",
            "Epoch 9/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7387 - loss: 0.1285\n",
            "Epoch 10/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7166 - loss: 0.1401\n",
            "Epoch 11/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7435 - loss: 0.1374\n",
            "Epoch 12/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7247 - loss: 0.1344\n",
            "Epoch 13/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7491 - loss: 0.1328\n",
            "Epoch 14/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7544 - loss: 0.1255\n",
            "Epoch 15/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7393 - loss: 0.1305\n",
            "Epoch 16/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7232 - loss: 0.1360\n",
            "Epoch 17/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7295 - loss: 0.1253\n",
            "Epoch 18/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7376 - loss: 0.1333\n",
            "Epoch 19/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7660 - loss: 0.1245\n",
            "Epoch 20/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7399 - loss: 0.1280\n",
            "Epoch 21/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7318 - loss: 0.1278\n",
            "Epoch 22/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7558 - loss: 0.1262\n",
            "Epoch 23/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7366 - loss: 0.1283\n",
            "Epoch 24/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7477 - loss: 0.1256\n",
            "Epoch 25/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7390 - loss: 0.1324\n",
            "Epoch 26/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7341 - loss: 0.1324\n",
            "Epoch 27/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7274 - loss: 0.1306\n",
            "Epoch 28/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7131 - loss: 0.1351\n",
            "Epoch 29/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7484 - loss: 0.1301\n",
            "Epoch 30/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7259 - loss: 0.1302 \n",
            "Epoch 31/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7165 - loss: 0.1312 \n",
            "Epoch 32/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7650 - loss: 0.1201 \n",
            "Epoch 33/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7377 - loss: 0.1336 \n",
            "Epoch 34/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7672 - loss: 0.1325 \n",
            "Epoch 35/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7122 - loss: 0.1435\n",
            "Epoch 36/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7688 - loss: 0.1208\n",
            "Epoch 37/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7525 - loss: 0.1241 \n",
            "Epoch 38/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7565 - loss: 0.1315 \n",
            "Epoch 39/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7594 - loss: 0.1232 \n",
            "Epoch 40/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7659 - loss: 0.1213 \n",
            "Epoch 41/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7602 - loss: 0.1276 \n",
            "Epoch 42/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7290 - loss: 0.1291 \n",
            "Epoch 43/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7297 - loss: 0.1304 \n",
            "Epoch 44/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7368 - loss: 0.1316\n",
            "Epoch 45/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7511 - loss: 0.1277\n",
            "Epoch 46/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7178 - loss: 0.1375\n",
            "Epoch 47/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7197 - loss: 0.1261 \n",
            "Epoch 48/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7751 - loss: 0.1190 \n",
            "Epoch 49/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7601 - loss: 0.1262\n",
            "Epoch 50/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7666 - loss: 0.1274 \n",
            "Epoch 51/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7463 - loss: 0.1256 \n",
            "Epoch 52/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7598 - loss: 0.1255 \n",
            "Epoch 53/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7513 - loss: 0.1268\n",
            "Epoch 54/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7672 - loss: 0.1302\n",
            "Epoch 55/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7737 - loss: 0.1215 \n",
            "Epoch 56/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7463 - loss: 0.1316 \n",
            "Epoch 57/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7661 - loss: 0.1245 \n",
            "Epoch 58/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7437 - loss: 0.1284 \n",
            "Epoch 59/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7817 - loss: 0.1318 \n",
            "Epoch 60/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7382 - loss: 0.1253 \n",
            "Epoch 61/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7777 - loss: 0.1173 \n",
            "Epoch 62/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7749 - loss: 0.1215\n",
            "Epoch 63/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7353 - loss: 0.1280\n",
            "Epoch 64/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7343 - loss: 0.1275 \n",
            "Epoch 65/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7489 - loss: 0.1266\n",
            "Epoch 66/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7141 - loss: 0.1299 \n",
            "Epoch 67/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7299 - loss: 0.1252 \n",
            "Epoch 68/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7582 - loss: 0.1250 \n",
            "Epoch 69/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7878 - loss: 0.1193 \n",
            "Epoch 70/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7637 - loss: 0.1279 \n",
            "Epoch 71/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7666 - loss: 0.1234 \n",
            "Epoch 72/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7385 - loss: 0.1262\n",
            "Epoch 73/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7655 - loss: 0.1257 \n",
            "Epoch 74/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7347 - loss: 0.1316 \n",
            "Epoch 75/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7474 - loss: 0.1218 \n",
            "Epoch 76/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7533 - loss: 0.1252 \n",
            "Epoch 77/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7696 - loss: 0.1215 \n",
            "Epoch 78/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7243 - loss: 0.1335 \n",
            "Epoch 79/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7706 - loss: 0.1346 \n",
            "Epoch 80/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7693 - loss: 0.1235 \n",
            "Epoch 81/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7194 - loss: 0.1236\n",
            "Epoch 82/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7340 - loss: 0.1319 \n",
            "Epoch 83/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7237 - loss: 0.1322 \n",
            "Epoch 84/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7468 - loss: 0.1307 \n",
            "Epoch 85/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7664 - loss: 0.1252 \n",
            "Epoch 86/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7457 - loss: 0.1255 \n",
            "Epoch 87/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7197 - loss: 0.1329 \n",
            "Epoch 88/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8125 - loss: 0.1151 \n",
            "Epoch 89/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7298 - loss: 0.1334 \n",
            "Epoch 90/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7435 - loss: 0.1275\n",
            "Epoch 91/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7479 - loss: 0.1279\n",
            "Epoch 92/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7795 - loss: 0.1243 \n",
            "Epoch 93/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7473 - loss: 0.1253 \n",
            "Epoch 94/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7197 - loss: 0.1338 \n",
            "Epoch 95/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7495 - loss: 0.1278 \n",
            "Epoch 96/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7608 - loss: 0.1244 \n",
            "Epoch 97/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7566 - loss: 0.1315 \n",
            "Epoch 98/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7396 - loss: 0.1278 \n",
            "Epoch 99/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7295 - loss: 0.1318 \n",
            "Epoch 100/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7662 - loss: 0.1259\n",
            "Epoch 1/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7331 - loss: 0.1334 - val_accuracy: 0.7805 - val_loss: 0.1120\n",
            "Epoch 2/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7439 - loss: 0.1329 - val_accuracy: 0.7805 - val_loss: 0.1118\n",
            "Epoch 3/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7253 - loss: 0.1288 - val_accuracy: 0.7805 - val_loss: 0.1118\n",
            "Epoch 4/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7312 - loss: 0.1323 - val_accuracy: 0.7805 - val_loss: 0.1119\n",
            "Epoch 5/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7327 - loss: 0.1343 - val_accuracy: 0.7805 - val_loss: 0.1116\n",
            "Epoch 6/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7533 - loss: 0.1284 - val_accuracy: 0.7805 - val_loss: 0.1119\n",
            "Epoch 7/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7134 - loss: 0.1344 - val_accuracy: 0.7805 - val_loss: 0.1119\n",
            "Epoch 8/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7544 - loss: 0.1300 - val_accuracy: 0.7805 - val_loss: 0.1118\n",
            "Epoch 9/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7394 - loss: 0.1335 - val_accuracy: 0.7805 - val_loss: 0.1116\n",
            "Epoch 10/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7566 - loss: 0.1292 - val_accuracy: 0.7805 - val_loss: 0.1116\n",
            "Epoch 11/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7212 - loss: 0.1306 - val_accuracy: 0.7805 - val_loss: 0.1115\n",
            "Epoch 12/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7272 - loss: 0.1365 - val_accuracy: 0.7805 - val_loss: 0.1116\n",
            "Epoch 13/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7581 - loss: 0.1241 - val_accuracy: 0.7805 - val_loss: 0.1115\n",
            "Epoch 14/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7269 - loss: 0.1345 - val_accuracy: 0.7805 - val_loss: 0.1116\n",
            "Epoch 15/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7107 - loss: 0.1328 - val_accuracy: 0.7805 - val_loss: 0.1115\n",
            "Epoch 16/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7250 - loss: 0.1275 - val_accuracy: 0.7805 - val_loss: 0.1115\n",
            "Epoch 17/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7386 - loss: 0.1288 - val_accuracy: 0.7805 - val_loss: 0.1112\n",
            "Epoch 18/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7145 - loss: 0.1338 - val_accuracy: 0.7886 - val_loss: 0.1110\n",
            "Epoch 19/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7039 - loss: 0.1357 - val_accuracy: 0.7886 - val_loss: 0.1109\n",
            "Epoch 20/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7230 - loss: 0.1310 - val_accuracy: 0.7886 - val_loss: 0.1109\n",
            "Epoch 21/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7686 - loss: 0.1218 - val_accuracy: 0.7886 - val_loss: 0.1110\n",
            "Epoch 22/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6935 - loss: 0.1413 - val_accuracy: 0.7886 - val_loss: 0.1108\n",
            "Epoch 23/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7560 - loss: 0.1349 - val_accuracy: 0.7886 - val_loss: 0.1109\n",
            "Epoch 24/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7397 - loss: 0.1349 - val_accuracy: 0.7886 - val_loss: 0.1108\n",
            "Epoch 25/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7280 - loss: 0.1370 - val_accuracy: 0.7886 - val_loss: 0.1108\n",
            "Epoch 26/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7551 - loss: 0.1344 - val_accuracy: 0.7967 - val_loss: 0.1107\n",
            "Epoch 27/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7252 - loss: 0.1311 - val_accuracy: 0.7886 - val_loss: 0.1110\n",
            "Epoch 28/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7363 - loss: 0.1286 - val_accuracy: 0.7886 - val_loss: 0.1108\n",
            "Epoch 29/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7792 - loss: 0.1152 - val_accuracy: 0.7886 - val_loss: 0.1109\n",
            "Epoch 30/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7737 - loss: 0.1207 - val_accuracy: 0.7886 - val_loss: 0.1112\n",
            "Epoch 31/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7397 - loss: 0.1294 - val_accuracy: 0.7805 - val_loss: 0.1115\n",
            "Epoch 32/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7587 - loss: 0.1240 - val_accuracy: 0.7805 - val_loss: 0.1114\n",
            "Epoch 33/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7513 - loss: 0.1286 - val_accuracy: 0.7805 - val_loss: 0.1116\n",
            "Epoch 34/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7026 - loss: 0.1424 - val_accuracy: 0.7805 - val_loss: 0.1115\n",
            "Epoch 35/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7645 - loss: 0.1267 - val_accuracy: 0.7805 - val_loss: 0.1114\n",
            "Epoch 36/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7030 - loss: 0.1334 - val_accuracy: 0.7805 - val_loss: 0.1112\n",
            "Epoch 37/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7850 - loss: 0.1234 - val_accuracy: 0.7805 - val_loss: 0.1114\n",
            "Epoch 38/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7393 - loss: 0.1292 - val_accuracy: 0.7805 - val_loss: 0.1114\n",
            "Epoch 39/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7467 - loss: 0.1261 - val_accuracy: 0.7805 - val_loss: 0.1116\n",
            "Epoch 40/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7385 - loss: 0.1284 - val_accuracy: 0.7805 - val_loss: 0.1117\n",
            "Epoch 41/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7238 - loss: 0.1388 - val_accuracy: 0.7805 - val_loss: 0.1116\n",
            "Epoch 42/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7351 - loss: 0.1342 - val_accuracy: 0.7805 - val_loss: 0.1116\n",
            "Epoch 43/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7116 - loss: 0.1332 - val_accuracy: 0.7805 - val_loss: 0.1117\n",
            "Epoch 44/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7422 - loss: 0.1272 - val_accuracy: 0.7805 - val_loss: 0.1116\n",
            "Epoch 45/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7489 - loss: 0.1269 - val_accuracy: 0.7805 - val_loss: 0.1115\n",
            "Epoch 46/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7522 - loss: 0.1351 - val_accuracy: 0.7805 - val_loss: 0.1115\n",
            "Epoch 47/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7357 - loss: 0.1283 - val_accuracy: 0.7805 - val_loss: 0.1113\n",
            "Epoch 48/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7639 - loss: 0.1294 - val_accuracy: 0.7886 - val_loss: 0.1111\n",
            "Epoch 49/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7350 - loss: 0.1221 - val_accuracy: 0.7886 - val_loss: 0.1110\n",
            "Epoch 50/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7746 - loss: 0.1260 - val_accuracy: 0.7886 - val_loss: 0.1108\n"
          ]
        }
      ],
      "source": [
        "history=model.fit(x_train,y_train,epochs=100)\n",
        "history =model.fit(x_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zRLGFZvTUIe-",
      "metadata": {
        "id": "zRLGFZvTUIe-"
      },
      "source": [
        "prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "id": "MsVZJZs-UKxG",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MsVZJZs-UKxG",
        "outputId": "529225c1-e36c-42bd-f7d7-51cf0de6177e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7862 - loss: 0.1198 \n",
            "loss:0.1272163838148117,accuracy:0.798701286315918\n"
          ]
        }
      ],
      "source": [
        "loss,accuracy=model.evaluate(x_test,y_test)\n",
        "print(f\"loss:{loss},accuracy:{accuracy}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "id": "blSNviu7XaNp",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blSNviu7XaNp",
        "outputId": "9c33b938-320e-4c77-be8f-e8565bfd5ae4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "predictions=model.predict(x_test)\n",
        "predictions=(predictions>0.5).astype(int).flatten()\n",
        "#print(predictions)\n",
        "model.save('diabetes.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(y_test, (predictions > 0.5).astype(int))\n",
        "# Extract confusion matrix components\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "# Compute metrics\n",
        "accuracy = accuracy_score(y_test, (predictions > 0.5).astype(int))\n",
        "precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "# Print summary\n",
        "print(\"Confusion Matrix Summary:\")\n",
        "print(f\"True Negatives (TN): {tn}\")\n",
        "print(f\"False Positives (FP): {fp}\")\n",
        "print(f\"False Negatives (FN): {fn}\")\n",
        "print(f\"True Positives (TP): {tp}\\n\")\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1-Score: {f1_score:.2f}\")\n",
        "predictions=predictions[:len(y_test)]\n",
        "from sklearn.calibration import calibration_curve\n",
        "print(len(y_test),len(predictions))\n",
        "#Compute calibration curve\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(y_test, (predictions > 0.5).astype(int))  # Thresholding at 0.5\n",
        "# Display confusion matrix\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"No Diabetes\", \"Diabetes\"])\n",
        "disp.plot(cmap=\"Blues\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "id": "ysDXK8S7dDzW",
        "outputId": "069c26e0-7073-49f9-b061-6a23d044555b"
      },
      "id": "ysDXK8S7dDzW",
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix Summary:\n",
            "True Negatives (TN): 78\n",
            "False Positives (FP): 21\n",
            "False Negatives (FN): 10\n",
            "True Positives (TP): 45\n",
            "\n",
            "Accuracy: 0.80\n",
            "Precision: 0.68\n",
            "Recall: 0.82\n",
            "F1-Score: 0.74\n",
            "154 154\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}